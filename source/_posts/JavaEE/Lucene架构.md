layout: '[layout]'
title: Lucene站内检索工具
date: 2015-06-03 22:21:13
categories: Lucene
tags: [框架,站内检索]
---
## 1 Lucene介绍
Lucene是apache软件基金会4 jakarta项目组的一个子项目，是一个开放源代码的全文检索引擎工具包，但它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎（英文与德文两种西方语言）。Lucene的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。Lucene是一套用于全文检索和搜寻的开源程式库，由Apache软件基金会支持和提供。Lucene提供了一个简单却强大的应用程式接口，能够做全文索引和搜寻。在Java开发环境里Lucene是一个成熟的免费开源工具。就其本身而言，Lucene是当前以及最近几年最受欢迎的免费Java信息检索程序库。人们经常提到信息检索程序库，虽然与搜索引擎有关，但不应该将信息检索程序库与搜索引擎相混淆。（百科）

## 2 相关术语：
文档（Document）：一般搜索引擎处理的对象是互联网网页，对于搜索引擎来讲，Word、PDF、html、XML等不同格式的文件都可以称为文档，一般以文档来表示文本信息。
文档集合（Document Collection）：由若干文档构成的集合成为文档集合。比如海量的互联网网页等。
文档编号（Document ID）：在搜索引擎内部，会为文档集合每个文档赋予一个唯一的内部编号，以作为文档的唯一标识，以便于处理。
单词编号（Word ID）：与文档编号类似，搜索引擎内部以唯一的编号来表示某个单词，以作为某个单词的唯一表示。
倒排索引（Inverted Index）：倒排索引是实现单词——文档矩阵的一种具体存储形式。通过倒排索引，可以根据单次快速获取包含这个单词的文档列表。倒排索引主要由两个部分组成：单词词典和倒排文件。
单词词典（Lexicon）：搜索引擎通常的索引单位是单词，单词词典是由文档集合中出现过的所有单词构成的字符串集合，单词词典内每条索引记载单词本身的一些信息及指向倒排列表的指针。单词也就是我们在搜索时的一些关键字，也称为词条。
倒排列表（PostingList）：倒排列表记载了出现过某个单词的所有文档的文档列表及单词在该文当中出现的位置信息，每条记录成为一个倒排向（Posting）。根据倒排列表，即可获知哪些文档包含某个单词。
倒排文件（Inverted File）：所有单词的倒排列表往往顺序地存储在磁盘的某个文件里，这个文件即为倒排文件，倒排文件是存储倒排索引的物理文件。

## 3 Lucene全文检索流程
### 3.1	创建索引和搜索流程
 ![](http://i.imgur.com/mEcapdv.png)

1. 创建索引过程，对要搜索的原始内容进行索引构建一个索引库，索引过程包括：
确定原始内容即要搜索的内容，获得文档，创建文档，分析文档，索引文档
2. 红色表示搜索过程，从索引库中搜索内容，搜索过程包括：
用户通过搜索界面，创建查询，执行搜索，从索引库搜索，渲染搜索结果

### 3.2	创建索引过程
1. 创建索引的过程其实就是将原始的文档数据创建索引并存储到索引库中的过程。
2. 创建document对象（文档）
3. 为文档添加Field
4. 创建建立索引对象IndexWriter
5. 将文档添加到索引库中
 
### 3.3	基于索引库检索过程
1. 将检索内容转成query对象 
2. 创建检索对象
3. 通过检索对象进行检索
4. 对检索的结果进行遍历

## 4 API
### 4.1 Document
Lucene创建索引时的原始文档。
### 4.2 IndexableField
1. LongField：long类型，会切词
2. StringField：string类型，通过StringField构建的字段不会被切词（分词）。
3. TextField：Text类型，会切词。
4. new XXXField(name：字段的名称,value：字段的值,store：是否存储到索引库中)
### 4.3 Directory
用来指定索引库存放的位置。
- Directory，指的是文件磁盘的索引路径
- RAMDirectory，指的是内存中的索引路径
### 4.4 Analyzer
#### 4.4.1 概念
在对Docuemnt中的内容进行索引之前，需要使用分词器进行分词 ，分词的目的是为了搜索。分词的主要过程就是先分词后过滤。
- 分词：采集到的数据会存储到document对象的Field域中，分词就是将Document中Field的value值切分成一个一个的词。
- 过滤：包括去除标点符号过滤、去除停用词过滤（的、是、a、an、the等）、大写转小写、词的形还原（复数形式转成单数形参、过去式转成现在式）等。 
- 注意：搜索使用的分析器要和索引使用的分析器一致
停用词：停用词是为节省存储空间和提高搜索效率，搜索引擎在索引页面或处理搜索请求时会自动忽略某些字或词，这些字或词即被称为Stop Words(停用词)。比如语气助词、副词、介词、连接词等，通常自身并无明确的意义，只有将其放入一个完整的句子中才有一定作用，如常见的“的”、“在”、“是”、“啊”等。

#### 4.4.2 中文分词器
学过英文的都知道，英文是以单词为单位的，单词与单词之间以空格或者逗号句号隔开。所以对于英文，我们可以简单以空格判断某个字符串是否为一个单词，比如I love China，love 和 China很容易被程序区分开来。
而中文则以字为单位，字又组成词，字和词再组成句子。中文“我爱中国”就不一样了，电脑不知道“中国”是一个词语还是“爱中”是一个词语。
把中文的句子切分成有意义的词，就是中文分词，也称切词。我爱中国，分词的结果是：我、爱、中国。
- StandardAnalyzer：
单字分词：就是按照中文一个字一个字地进行分词。如：“我爱中国”，
效果：“我”、“爱”、“中”、“国”。
- CJKAnalyzer
二分法分词：按两个字进行切分。如：“我是中国人”，效果：“我是”、“是中”、“中国”“国人”
#### 4.4.3 第三方的中文分词器
1. paoding
庖丁解牛最新版在 https://code.google.com/p/paoding/ 中最多支持Lucene 3.0，且最新提交的代码在 2008-06-03，在svn中最新也是2010年提交，已经过时，不予考虑。
2. mmseg4j
最新版已从 https://code.google.com/p/mmseg4j/ 移至 https://github.com/chenlb/mmseg4j-solr，支持Lucene 4.10，且在github中最新提交代码是2014年6月，从09年～14年一共有：18个版本，也就是一年几乎有3个大小版本，有较大的活跃度，用了mmseg算法。
3. IK-analyzer
最新版在https://code.google.com/p/ik-analyzer/上，支持Lucene 4.10从2006年12月推出1.0版开始， IKAnalyzer已经推出了4个大版本。最初，它是以开源项目Luence为应用主体的，结合词典分词和文法分析算法的中文分词组件。从3.0版本开 始，IK发展为面向Java的公用分词组件，独立于Lucene项目，同时提供了对Lucene的默认优化实现。在2012版本中，IK实现了简单的分词 歧义排除算法，标志着IK分词器从单纯的词典分词向模拟语义分词衍化。 但是也就是2012年12月后没有在更新。
4. ansj_seg
最新版本在 https://github.com/NLPchina/ansj_seg tags仅有1.1版本，从2012年到2014年更新了大小6次，但是作者本人在2014年10月10日说明：“可能我以后没有精力来维护ansj_seg了”，现在由”nlp_china”管理。2014年11月有更新。并未说明是否支持Lucene，是一个由CRF（条件随机场）算法所做的分词算法。
5. imdict-chinese-analyzer
最新版在 https://code.google.com/p/imdict-chinese-analyzer/ ， 最新更新也在2009年5月，下载源码，不支持Lucene 4.10 。是利用HMM（隐马尔科夫链）算法。

### 4.5 基于索引库的检索的API
1. QueryParser:根据哪个字段并分词检索。
2. MultiFieldQueryParser:指定多个字段检索并分词
3. TermQuery:根据词条进行检索，不会切词了，因为词条已是最小单位。
4. WildcardQuery:模糊检索
5. FuzzyQuery:相似度检索
FuzzyQuery的构造方法：
FuzzyQuery(Term term)：默认支持模糊字数为2；
FuzzyQuery(Term term, int maxEdits)：maxEdits：模糊字数，[0,2]之间，若为0，相当于TermQuery。
FuzzyQuery(Term term, int maxEdits, int prefixLength)：prefixLength，指定要有多个前缀字母必须完全匹配。
6. NumericRangeQuery：数字范围搜索（演示：略），最后两个参数的含义是：minInclusive，是否最小包含，maxInclusive，是否最大包含
7. MatchAllDocsQuery：查询所有
8. BooleanQuery：组合查询
1、MUST和MUST表示“与”的关系，即“交集”，相当与AND。 
2、MUST和MUST_NOT前者包含后者不包含。 
3、MUST_NOT和MUST_NOT没意义 
4、SHOULD与MUST表示MUST，SHOULD失去意义； 
5、SHOULD与MUST_NOT相当于MUST与MUST_NOT。 
6、SHOULD与SHOULD表示“或”的关系，相当与OR。

Lucene和搜索引擎不同，Lucene是一套用java或其它语言写的全文检索的工具包，为应用程序提供了很多个api接口去调用，可以简单理解为是一套实现全文检索的类库，搜索引擎是一个全文检索系统，它是一个单独运行的软件系统。
